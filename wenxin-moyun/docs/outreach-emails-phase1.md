# VULCA å¤–è”é‚®ä»¶ - Phase 1

**ç”Ÿæˆæ—¥æœŸ**: 2026-01-21
**æ€»è®¡**: 10 å°é‚®ä»¶
**çŠ¶æ€**: âœ… å·²å…¨éƒ¨å‘é€ (2026-01-23)

---

## ç­¾åæ¨¡æ¿

```
Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 1: Ahmad Rushdi - Stanford HAI

**To**: rushdi@stanford.edu
**Subject**: Cultural VLM benchmark - collaboration with Stanford HAI?

```
Hi Ahmad,

I came across Stanford HAI's industry collaboration program and thought VULCA might be a good fit for discussion.

We've built a multicultural evaluation benchmark specifically for Vision-Language Models:

â€¢ 47 evaluation dimensions across 8 cultural traditions
â€¢ 7,410 expert-annotated image-critique pairs (EN/ZH bilingual)
â€¢ L1-L5 framework: Visual Perception â†’ Philosophical Aesthetics
â€¢ Already tested on 42+ models including GPT-4V, Gemini, Claude, Qwen-VL

Given HAI's focus on human-centered AI and the 2025 AI Index findings on capability gaps, VULCA could provide valuable cultural understanding metrics for multimodal benchmarking.

Would you have 15 minutes to explore potential collaboration?

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 2: Glenn Wong - MIT CSAIL (æ›¿æ¢ Lori Gloverï¼Œå·²ç¦»èŒ)

**To**: glennw@mit.edu
**Subject**: Multimodal cultural evaluation benchmark - industry collaboration inquiry

```
Dear Glenn,

I'm reaching out to the CSAIL Alliances team regarding potential industry collaboration. I understand you're leading the global strategic alliances program, and thought VULCA might align well with CSAIL's industry collaboration initiatives.

We've developed VULCA, a benchmark that evaluates how well Vision-Language Models understand cultural context in visual art - an area that complements CSAIL's work on multimodal interpretability (like the recent MAIA project).

Key capabilities:
â€¢ 47 culture-specific evaluation dimensions
â€¢ Expert-annotated bilingual critiques (7,410 pairs)
â€¢ Tested on 42+ frontier models
â€¢ Framework spans perception to philosophical aesthetics (L1-L5)

We're interested in exploring:
1. Joint benchmark validation studies
2. Sponsored research pilots
3. Student project collaborations

Would your team be open to a brief introductory call?

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 3: Prof. Danqi Chen - Princeton NLP

**To**: danqic@cs.princeton.edu
**Subject**: Collaboration opportunity - multicultural VLM evaluation benchmark

```
Dear Prof. Chen,

I came across your CharXiv work on chart understanding in multimodal LLMs, and thought our research directions might align well.

We've developed VULCA-Bench, a multicultural art-critique benchmark that evaluates VLMs' cultural understanding beyond surface-level visual perception. Our framework:

â€¢ 47 dimensions across 8 cultural traditions (Chinese, Western, Japanese, etc.)
â€¢ 7,410 matched image-critique pairs with expert annotations
â€¢ Bilingual coverage (EN/ZH)
â€¢ L1-L5 hierarchy: Visual Perception â†’ Philosophical Aesthetics

Our pilot results show that higher-layer cultural reasoning (L3-L5) is consistently more challenging than visual analysis - similar patterns to what you've observed in chart understanding.

I'd love to share a sample evaluation report and discuss potential collaboration - whether for benchmark validation or joint publications.

Would you have 10 minutes for a brief introduction?

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 4: Sarah Clayton - Oxford Engineering Science

**To**: sarah.clayton@eng.ox.ac.uk
**Subject**: Introduction inquiry - VLM cultural evaluation research at Oxford

```
Dear Sarah,

I'm reaching out from the VULCA team. I understand you're the Programme Manager for Engineering Science, and I was hoping you might be able to point me in the right direction.

We've developed a cultural understanding benchmark for Vision-Language Models that may be of interest to researchers in the Visual Geometry Group or related multimodal AI research areas at Oxford.

VULCA evaluates how well AI models interpret artistic symbolism, cultural context, and aesthetic meaning - spanning 47 evaluation dimensions across 8 cultural traditions, with 7,410 expert-annotated image-critique pairs.

Could you suggest the most appropriate contact for discussing potential research collaboration or benchmark adoption? Alternatively, if there's a better channel for academic partnership inquiries, I'd appreciate any guidance.

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 5: Promptfoo - AI Security

**To**: inquiries@promptfoo.dev
**Subject**: Cultural evaluation module for multimodal red teaming

```
Hi Promptfoo Team,

I saw your multimodal red teaming guide and think VULCA could be a valuable addition to your evaluation toolkit.

We've built a specialized cultural understanding benchmark for VLMs that tests:

â€¢ Symbolic interpretation (religious, cultural, historical symbols)
â€¢ Cross-cultural context understanding
â€¢ Aesthetic judgment and critique generation
â€¢ Cultural bias detection across 8 traditions

This complements your existing multimodal red teaming by adding a "culture & symbolism" test suite - high-signal for applications in media, creative tools, and public-facing AI.

Quick stats:
- 47 evaluation dimensions
- 7,410 expert-annotated test cases
- Bilingual coverage (EN/ZH)
- Already benchmarked 42+ frontier models

Interested in exploring a partnership or integration?

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 6: Berkman Klein Center - Harvard

**To**: hello@cyber.harvard.edu
**Subject**: Cultural fairness evaluation for multimodal AI - research collaboration

```
Hello BKC Team,

I'm reaching out regarding the intersection of AI fairness and cultural representation - an area I believe aligns with Berkman Klein's mission.

We've developed VULCA, an evaluation framework that measures how well Vision-Language Models understand and represent diverse cultural perspectives. Our research reveals:

â€¢ Consistent Western bias across major VLMs
â€¢ Performance gaps of 15-25% between Western and non-Western cultural content
â€¢ Higher-layer cultural reasoning (philosophical, aesthetic) is significantly harder than visual perception

Our benchmark covers:
- 8 cultural traditions (Chinese, Western, Japanese, Islamic, etc.)
- 47 evaluation dimensions
- 7,410 expert-annotated image-critique pairs

This could provide concrete, measurable evidence for AI fairness discussions around cultural representation.

Would your team be interested in exploring collaboration opportunities?

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 7: Alan Turing Institute - Partnerships

**To**: partnerships-and-engagement@turing.ac.uk
**Subject**: Cultural AI evaluation benchmark - UK partnership opportunity

```
Hello Turing Partnerships Team,

I'm reaching out regarding a potential collaboration around AI evaluation methodology.

We've built VULCA, a benchmark that evaluates Vision-Language Models' cultural understanding - specifically their ability to interpret art, symbolism, and aesthetic meaning across different cultural traditions.

Why this matters for Turing:
â€¢ Addresses cultural bias in multimodal AI (a growing research priority)
â€¢ Provides measurable metrics for responsible AI development
â€¢ Bridges AI research with digital humanities

Our framework:
- 47 culture-specific evaluation dimensions
- 8 cultural traditions covered
- 7,410 expert-annotated test cases
- Tested on 42+ frontier models

We're interested in exploring:
1. Research collaboration or validation studies
2. UK-focused cultural heritage AI applications
3. Joint events or publications

Would you have 15 minutes to discuss potential synergies?

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 8: Metropolitan Museum - Open Access

**To**: openaccess@metmuseum.org
**Subject**: AI evaluation for cultural heritage interpretation - pilot opportunity

```
Hello Met Open Access Team,

I'm reaching out regarding the Met's pioneering Open Access initiative and its intersection with AI-powered interpretation tools.

As museums increasingly adopt AI for collection interpretation, accessibility, and public engagement, we've developed VULCA - a specialized evaluation framework that assesses how well AI models understand cultural context and artistic symbolism.

What we offer:
â€¢ Evaluation of AI interpretation accuracy across cultural traditions
â€¢ Benchmark testing on 42+ vision-language models
â€¢ Insights into which AI tools best preserve cultural nuance

Potential collaboration:
1. Pilot evaluation using Met Open Access collection data
2. Assessment of AI-powered interpretation tools
3. Case study for cultural heritage AI best practices

This could help ensure the Met's digital experiences maintain the cultural accuracy and depth your collections deserve.

Would your team be interested in exploring a pilot project?

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 9: Georgia Mallin - British Museum Knowledge Exchange

**To**: gmallin@britishmuseum.org
**Subject**: AI cultural understanding evaluation - knowledge exchange opportunity

```
Dear Georgia,

I'm reaching out through the British Museum's Knowledge Exchange program regarding AI and cultural heritage interpretation.

We've developed VULCA, an evaluation framework that measures how well AI systems understand cultural context, symbolism, and artistic meaning - directly relevant as museums adopt AI for collection interpretation and public engagement.

Our work could support the British Museum by:

1. Evaluating AI interpretation tools for cultural accuracy
2. Identifying which AI models best understand diverse cultural traditions
3. Providing metrics for responsible AI deployment in heritage contexts

Key capabilities:
- 47 evaluation dimensions across 8 cultural traditions
- 7,410 expert-annotated test cases
- Benchmarked 42+ frontier AI models
- Bilingual framework (relevant for global collections)

Would you be open to a brief call to explore collaboration opportunities?

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## é‚®ä»¶ 10: Advance AI Safety Today (ai-evaluation.org)

**To**: info@ai-evaluation.org
**Subject**: Multicultural VLM evaluation benchmark - case study opportunity

```
Hello AI Evaluation Team,

Your mission to advance AI evaluation methodology aligns directly with our work at VULCA.

We've built a multicultural evaluation benchmark specifically for Vision-Language Models - addressing a gap in current evaluation frameworks around cultural understanding and representation.

VULCA provides:
â€¢ 47 culture-specific evaluation dimensions
â€¢ Coverage of 8 cultural traditions
â€¢ 7,410 expert-annotated image-critique pairs
â€¢ L1-L5 hierarchy from visual perception to philosophical aesthetics
â€¢ Bilingual framework (EN/ZH)

Key findings from our benchmark:
- Consistent Western bias across all tested VLMs
- Higher-layer cultural reasoning significantly harder than visual tasks
- 15-25% performance gaps between Western and non-Western content

We'd be interested in contributing VULCA as a case study for multimodal cultural evaluation, or exploring how our methodology could inform broader AI evaluation standards.

Would you have time for a brief call?

Best regards,

VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

ğŸ”— Learn more: https://vulcaart.art
ğŸ“… Book a demo: https://cal.com/vulcaart/demo
```

---

## å‘é€è·Ÿè¸ªè¡¨

| # | æ”¶ä»¶äºº | é‚®ç®± | å‘é€æ—¥æœŸ | çŠ¶æ€ | å›å¤æ—¥æœŸ | å¤‡æ³¨ |
|---|--------|------|----------|------|----------|------|
| 1 | Ahmad Rushdi | rushdi@stanford.edu | 2026-01-23 | âœ… å·²å‘é€ | âœ… å·²å›å¤ | Stanford HAI äº§ä¸šåˆä½œ |
| 2 | Glenn Wong (æ›¿æ¢ Lori Glover) | glennw@mit.edu | 2026-01-23 | âœ… å·²å‘é€ | | âš ï¸ Lori å·²ç¦»èŒ |
| 3 | Danqi Chen | danqic@cs.princeton.edu | 2026-01-23 | âœ… å·²å‘é€ | | Princeton NLP |
| 4 | Sarah Clayton | sarah.clayton@eng.ox.ac.uk | 2026-01-23 | âœ… å·²å‘é€ | | äº§å‡ä¸­ï¼Œ2026å¹´3æœˆå› |
| 5 | Promptfoo | inquiries@promptfoo.dev | 2026-01-23 | âœ… å·²å‘é€ | | AI Security |
| 6 | BKC Harvard | hello@cyber.harvard.edu | 2026-01-23 | âœ… å·²å‘é€ | è‡ªåŠ¨å›å¤ | Berkman Klein Center |
| 7 | Turing Institute | partnerships-and-engagement@turing.ac.uk | 2026-01-23 | âœ… å·²å‘é€ | è‡ªåŠ¨å›å¤ | Alan Turing Institute |
| 8 | Met Museum | openaccess@metmuseum.org | 2026-01-23 | âœ… å·²å‘é€ | | Open Access Team |
| 9 | Georgia Mallin | gmallin@britishmuseum.org | 2026-01-23 | âœ… å·²å‘é€ | | British Museum |
| 10 | ai-evaluation.org | info@ai-evaluation.org | 2026-01-23 | âœ… å·²å‘é€ | âœ… å·²å›å¤ | Advance AI Safety Today |

---

## Follow-up æ¨¡æ¿ï¼ˆ7 å¤©åä½¿ç”¨ï¼‰

**Subject**: Re: [åŸé‚®ä»¶ä¸»é¢˜]

```
Hi [Name],

Just following up on my previous email about VULCA - our cultural evaluation benchmark for VLMs.

I know you're busy, so here's the quick version:
â€¢ We evaluate how well AI understands cultural context in art
â€¢ 47 dimensions, 8 cultural traditions, 42+ models tested
â€¢ Results show consistent Western bias across all major VLMs

Happy to share a sample report if that's easier than a call.

Best,
VULCA Team
```

---

*ç”Ÿæˆäº 2026-01-21 by Claude Code*
