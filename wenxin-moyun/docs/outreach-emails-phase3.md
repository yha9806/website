# VULCA 外联邮件 - Phase 3

**生成日期**: 2026-01-25
**发送日期**: 2026-01-25
**总计**: 10 封邮件 (9 封已发送，1 封需 LinkedIn)
**重点**: 学术研究者 + 文化机构
**状态**: ✅ 9/10 已完成 (Val Ravaglia 待 LinkedIn)

---

## 验证状态汇总

| # | 姓名 | 机构 | 邮箱 | 验证分数 | 状态 |
|---|------|------|------|----------|------|
| 1 | 王晋东 | William & Mary | jwang80@wm.edu | 7/7 | 可发送 |
| 2 | 冯雁 | HKUST / Meta | pascale@ust.hk | 7/7 | 可发送 |
| 3 | Paul Pu Liang | MIT | ppliang@mit.edu | 7/7 | 可发送 |
| 4 | Yi R. Fung | HKUST | yrfung@ust.hk | 7/7 | 可发送 |
| 5 | Trevor Darrell | UC Berkeley | trevor@eecs.berkeley.edu | 7/7 | 可发送 |
| 6 | Val Ravaglia | Tate Modern | LinkedIn | 6/7 | 需 LinkedIn |
| 7 | Sarah Schwettmann | MIT / Transluce | sarah@transluce.org | 7/7 | 可发送 |
| 8 | Louis-Philippe Morency | CMU | morency@cs.cmu.edu | 7/7 | 可发送 |
| 9 | British Museum | Corporate Support | corporatesupport@britishmuseum.org | 6/7 | 可发送 |
| 10 | 杨浩 | 北大 | yanghao2008@pku.edu.cn | 7/7 | 可发送 |

---

## 签名模板

```
Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 1: 王晋东 (Jindong Wang) - William & Mary

**To**: jwang80@wm.edu
**Subject**: CultureVLM meets VULCA - potential collaboration on cultural VLM evaluation

**验证记录**:
- 姓名: Jindong Wang (王晋东) - 个人网站 jd92.wang 确认
- 职位: Assistant Professor of Data Science - W&M 官网确认
- 在职: 2025年11月获 Google + AWS 双奖
- 邮箱: jwang80@wm.edu - CultureVLM 论文通讯作者邮箱
- 验证分数: 7/7

```
Dear Prof. Wang,

I came across CultureVLM and was impressed by the scope - 19,682 cultural concepts across 188 countries is remarkable work. I'm reaching out because our research directions are highly complementary.

I'm the first author of VULCA (EMNLP 2025 Findings), a framework for evaluating VLMs' understanding of traditional Chinese painting. Our approaches differ but address the same fundamental question: how well do VLMs understand cultural context?

Key differences that could be synergistic:
- CultureVLM: Broad coverage (188 countries), knowledge-based QA
- VULCA: Deep coverage (47 dimensions, L1-L5 hierarchy), critique generation
- CultureVLM: Cultural concepts and customs
- VULCA: Artistic symbolism and aesthetic reasoning

I believe combining breadth (CultureVLM) with depth (VULCA) could create a more comprehensive cultural evaluation suite. Would you be interested in exploring collaboration? Some possibilities:

1. Joint benchmark combining both approaches
2. Cross-evaluation: test CultureVLM-trained models on VULCA tasks
3. Co-authorship on a survey/position paper on cultural VLM evaluation

I'd be happy to share our full dataset and methodology. Congratulations on the Google and AWS awards - well deserved recognition for important work.

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 2: 冯雁 (Pascale Fung) - HKUST / Meta

**To**: pascale@ust.hk
**Subject**: Cultural alignment in VLMs - VULCA benchmark collaboration

**验证记录**:
- 姓名: Pascale Fung (冯雁) - HKUST ECE 官网确认
- 职位: Chair Professor (HKUST) + Senior Director AI Research (Meta-FAIR)
- 在职: ACL 2025 Industry Track 演讲者
- 邮箱: pascale@ust.hk - HKUST 官网确认
- 验证分数: 7/7

```
Dear Prof. Fung,

Your work on UniVaR and high-dimension human value representation in LLMs directly addresses questions we're exploring with VULCA - how do we measure and improve cultural understanding in multimodal AI?

I'm the first author of VULCA (EMNLP 2025 Findings), a benchmark evaluating VLMs' understanding of traditional Chinese painting across 47 dimensions and 8 cultural perspectives. Our L1-L5 hierarchy (Visual Perception → Philosophical Aesthetics) reveals that cultural reasoning at higher layers is consistently harder - a finding that may complement your cross-cultural value alignment research.

Given your dual role at HKUST and Meta-FAIR, I thought VULCA might be relevant for:

1. **Research**: Cultural dimension for multimodal value alignment
2. **Meta-FAIR**: Evaluation of Llama models on artistic/cultural tasks
3. **CAiRE**: Potential student collaboration or benchmark adoption

Our dataset covers 7,410 expert-annotated image-critique pairs with bilingual coverage (EN/ZH). I'd be happy to share a sample evaluation report showing how different VLMs perform across cultural dimensions.

Would you have 15 minutes to discuss potential synergies?

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 3: Paul Pu Liang - MIT

**To**: ppliang@mit.edu
**Subject**: VULCA - cultural dimension for multimodal evaluation (complementing MultiBench/HEMM)

**验证记录**:
- 姓名: Paul Pu Liang - MIT EECS 官网确认
- 职位: Assistant Professor, Media Arts and Sciences & EECS
- 在职: 2024年9月加入 MIT，2025春教授课程
- 邮箱: ppliang@mit.edu - MIT EECS 官网确认
- 验证分数: 7/7

```
Dear Prof. Liang,

Congratulations on joining MIT and establishing the Multisensory Intelligence group! I've followed your work since the awesome-multimodal-ml days, and MultiBench has been influential for our research.

I'm reaching out about VULCA (EMNLP 2025 Findings), a benchmark we've developed for evaluating VLMs' cultural understanding - specifically in the domain of traditional art criticism. I believe it addresses a gap that MultiBench and HEMM don't currently cover: deep cultural reasoning.

What VULCA offers:
- 47 evaluation dimensions across 8 cultural traditions
- L1-L5 hierarchy: Visual Perception → Philosophical Aesthetics
- 7,410 expert-annotated image-critique pairs (EN/ZH bilingual)
- Tested on 42+ models including GPT-4V, Gemini, Claude, Qwen-VL

Key finding: Models that excel on standard multimodal benchmarks often fail at higher-layer cultural reasoning (L3-L5). This suggests cultural understanding may be an underserved dimension in current evaluation paradigms.

Given your focus on holistic multimodal evaluation (HEMM), would you be interested in:
1. Adding VULCA as a cultural reasoning component?
2. Collaborating on a cultural extension of multimodal benchmarking?
3. Having me present VULCA at a Multisensory Intelligence group meeting?

I'd be happy to share our methodology and discuss how VULCA could complement your evaluation infrastructure.

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 4: Yi R. Fung (May) - HKUST

**To**: yrfung@ust.hk
**Subject**: CultureAtlas + VULCA - complementary approaches to cultural AI evaluation

**验证记录**:
- 姓名: May Yi Ren Fung - HKUST 官网确认
- 职位: Assistant Professor, CSE, HKUST
- 在职: 2024年从 UIUC 获博士后加入 HKUST
- 邮箱: yrfung@ust.hk - HKUST Faculty Profile 确认
- 验证分数: 7/7

```
Dear Prof. Fung,

Congratulations on joining HKUST and on the ACL'24 and NAACL'24 Outstanding Paper awards! CultureAtlas's coverage of 193 countries and 2,557 ethnolinguistic groups is impressive work.

I'm reaching out because I believe our research is highly complementary. I'm the first author of VULCA (EMNLP 2025 Findings), which takes a "depth over breadth" approach to cultural VLM evaluation:

| Dimension | CultureAtlas | VULCA |
|-----------|--------------|-------|
| Coverage | 193 countries, 2557 groups | 8 cultural traditions |
| Task Type | Knowledge QA | Critique generation |
| Depth | Cultural facts | 47 dimensions, L1-L5 hierarchy |
| Domain | General cultural knowledge | Art & aesthetics |

I think there's a compelling case for combining these approaches - breadth (CultureAtlas) with depth (VULCA) - to create a more comprehensive cultural AI evaluation suite.

Since you're at HKUST, you might also be interested to know that Prof. Pascale Fung's work on UniVaR explores similar questions from a value alignment perspective. Perhaps there's potential for a HKUST-based cultural AI evaluation initiative?

Would you be open to a brief call to explore collaboration possibilities?

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 5: Trevor Darrell - UC Berkeley BAIR

**To**: trevor@eecs.berkeley.edu
**Subject**: Cultural understanding benchmark for vision-language models - BAIR collaboration

**验证记录**:
- 姓名: Trevor Darrell - UC Berkeley EECS 官网确认
- 职位: Professor, EECS; Co-Director, BAIR
- 在职: 2025 Embedded Vision Summit 演讲者
- 邮箱: trevor@eecs.berkeley.edu - EECS 官网确认
- 验证分数: 7/7

```
Dear Prof. Darrell,

I'm reaching out regarding cultural understanding evaluation for vision-language models - an area I believe BAIR could help advance.

I'm the first author of VULCA (EMNLP 2025 Findings), a benchmark that evaluates how well VLMs understand cultural context in visual art. Our framework reveals consistent gaps in cultural reasoning across all major models:

Key findings:
- 15-25% performance gaps between Western and non-Western cultural content
- Higher-layer reasoning (philosophical, aesthetic) significantly harder than visual perception
- Models trained on Western-centric data systematically underperform on East Asian art

Given your leadership of BAIR and Berkeley DeepDrive, and your teaching of CS294-43 (Large Scale Vision and Language Models), I thought this might be relevant for:

1. Incorporating cultural evaluation into VLM research at BAIR
2. Case study for your course on VLM limitations
3. Collaboration with LMArena (given your Berkeley connections) on cultural leaderboard dimensions

Our benchmark covers 47 dimensions across 8 cultural traditions, with 7,410 expert-annotated test cases. I'd be happy to share our methodology and discuss how VULCA could inform BAIR's multimodal research.

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 6: Val Ravaglia - Tate Modern (LinkedIn)

**Platform**: LinkedIn InMail
**Profile**: linkedin.com/in/val-ravaglia-9b768049/

**验证记录**:
- 姓名: Dr. Val (Valentina) Ravaglia - Tate Press Release 确认
- 职位: Curator, Displays & International Art, Tate Modern
- 在职: Electric Dreams 展览策展人 (2024.11-2025.06)
- 邮箱: 无公开邮箱
- 验证分数: 6/7

```
Dear Dr. Ravaglia,

I was fascinated by Electric Dreams and Anthropic's involvement in exploring the intersection of art and technology. Your curatorial work on pre-internet tech art raises questions that remain relevant for AI today.

I'm reaching out to introduce VULCA, an AI evaluation platform I developed that measures how well AI models understand art and cultural context. Given your collaboration with Anthropic on Electric Dreams, I thought this might be relevant.

What VULCA offers:
- Evaluation of AI interpretation accuracy across 8 cultural traditions
- 47 dimensions covering technique, symbolism, and aesthetic meaning
- Expert-annotated by art historians and critics
- Tested on 42+ AI models including Claude

Our research shows that even the most advanced AI models struggle with deeper cultural and aesthetic reasoning - the kind of understanding that curators like yourself bring to exhibition design.

I'd love to discuss how VULCA could:
1. Inform Tate's approach to AI-assisted interpretation tools
2. Provide evaluation metrics for responsible AI use in museums
3. Contribute to ongoing conversations about AI and art

Would you be open to a brief conversation?

Best regards,
Haorui Yu
VULCA Team | vulcaart.art
```

---

## 邮件 7: Sarah Schwettmann - MIT / Transluce

**To**: sarah@transluce.org
**Subject**: Cultural interpretability for VLMs - VULCA benchmark

**验证记录**:
- 姓名: Sarah Schwettmann - MIT Rising Stars 确认
- 职位: Research Scientist (MIT CSAIL) + Co-Founder/CSO (Transluce)
- 在职: MATS Summer 2026 导师
- 邮箱: sarah@transluce.org - LinkedIn 公开
- 验证分数: 7/7

```
Dear Sarah,

Your work on MAIA and automated interpretability is exactly the kind of approach I believe is needed for understanding cultural biases in AI systems.

I'm reaching out about VULCA (EMNLP 2025 Findings), a benchmark I developed for evaluating VLMs' cultural understanding. While MAIA focuses on interpreting what models see and represent, VULCA reveals what they fail to understand culturally.

Potential intersection:
- MAIA helps explain *how* models process visual information
- VULCA identifies *where* cultural understanding breaks down
- Together: interpretability tools for diagnosing cultural biases

Our L1-L5 framework (Visual Perception → Philosophical Aesthetics) might provide useful task decomposition for interpretability research - we can pinpoint exactly which layer of cultural reasoning fails.

Given Transluce's mission to "understand AI systems and steer them in the public interest," cultural understanding seems highly relevant. I'd love to explore:

1. Using MAIA-style agents to interpret cultural failures identified by VULCA
2. Contributing VULCA as a domain-specific benchmark for Transluce
3. Collaboration on culturally-aware interpretability research

Would you be interested in discussing this further?

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 8: Louis-Philippe Morency - CMU

**To**: morency@cs.cmu.edu
**Subject**: Cultural dimension for multimodal ML - VULCA benchmark

**验证记录**:
- 姓名: Louis-Philippe Morency - CMU SCS 官网确认
- 职位: Leonardo Associate Professor, LTI, CMU
- 在职: MultiComp Lab 负责人
- 邮箱: morency@cs.cmu.edu - 官网确认
- 验证分数: 7/7

```
Dear Prof. Morency,

Your pioneering work on multimodal machine learning has shaped how the field approaches cross-modal understanding. I'm reaching out about a dimension that I believe deserves more attention: cultural context.

I'm the first author of VULCA (EMNLP 2025 Findings), a benchmark evaluating VLMs' understanding of traditional art across cultural traditions. Our work is inspired by the multimodal foundations you've established - but applied to the challenging domain of cultural reasoning.

What we found:
- Multimodal models consistently fail at higher-layer cultural reasoning
- Performance gaps of 15-25% between Western and non-Western content
- The L1-L5 hierarchy (Visual → Philosophical) reveals systematic weaknesses

Given MultiComp Lab's focus on human communicative behaviors and social interactions, cultural context seems highly relevant. Art criticism is, after all, a form of multimodal social communication.

I'd be honored to:
1. Present VULCA at a MultiComp Lab meeting
2. Discuss how cultural evaluation could extend multimodal benchmarking
3. Explore collaboration opportunities with your students (I noticed Paul Liang's impressive trajectory from your lab!)

Would you have time for a brief call?

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 9: British Museum - Corporate Support

**To**: corporatesupport@britishmuseum.org
**Subject**: AI cultural understanding evaluation - partnership opportunity for museum AI tools

**验证记录**:
- 机构: The British Museum
- 部门: Corporate Support
- 邮箱: corporatesupport@britishmuseum.org - 官网确认
- 验证分数: 6/7

```
Dear British Museum Corporate Partnerships Team,

I'm reaching out regarding the intersection of AI and cultural heritage interpretation - an area of growing importance as museums adopt AI-powered tools.

VULCA is an AI evaluation platform that measures how accurately AI systems understand cultural context, symbolism, and artistic meaning. As institutions like the British Museum increasingly explore AI for collection interpretation and public engagement, ensuring cultural accuracy becomes critical.

What VULCA offers museums:
- Evaluation of AI interpretation tools across 8 cultural traditions
- 47 assessment dimensions covering technique, context, and meaning
- Expert-validated methodology developed with art historians
- Benchmarking against 42+ AI models

Potential collaboration areas:
1. **Pilot evaluation** of AI-powered interpretation tools the Museum is considering
2. **Cultural accuracy certification** for AI-assisted collection descriptions
3. **Joint research** on responsible AI deployment in heritage contexts
4. **Case study** demonstrating best practices for museum AI evaluation

I understand the British Museum has partnerships with leading technology companies. VULCA could help ensure that AI tools deployed in your galleries maintain the cultural depth and accuracy your collections deserve.

Could you please direct this inquiry to the appropriate team member for technology partnerships? I'd welcome the opportunity to discuss how VULCA could support the Museum's digital strategy.

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 10: 杨浩 - 北京大学

**To**: yanghao2008@pku.edu.cn
**Subject**: VULCA 视觉语言模型文化理解评测 - 数字人文合作探讨

**验证记录**:
- 姓名: 杨浩 - 北大 AI 研究院官网确认
- 职位: 副研究员 + 数字人文中心副主任
- 在职: 官网 Profile 活跃
- 邮箱: yanghao2008@pku.edu.cn - 官网确认
- 验证分数: 7/7

```
杨浩老师您好，

我在了解"识典古籍"平台时注意到您在数字人文与人工智能结合方面的工作，非常钦佩。我是 VULCA 项目的第一作者（EMNLP 2025 Findings），想就视觉语言模型的文化理解评测与您探讨合作可能。

VULCA 是一个评估 AI 模型理解中国传统绘画能力的基准测试框架：

核心特点：
- 47 个评测维度，覆盖 8 种文化传统
- L1-L5 层级体系：视觉感知 → 哲学美学
- 7,410 个专家标注的图像-评论对（中英双语）
- 已测试 42+ 个主流模型（GPT-4V、Gemini、Claude、通义千问等）

主要发现：
- 所有模型在高层文化推理（L3-L5）上表现显著弱于视觉感知
- 西方内容与非西方内容存在 15-25% 的性能差距
- 文化符号误读是常见失败模式

我认为 VULCA 与"识典古籍"的工作有很强的互补性：
- 识典古籍：文本层面的古籍智能处理（标点、翻译、校对）
- VULCA：视觉层面的文化理解评测（绘画、书法、艺术品）

可能的合作方向：
1. 将 VULCA 扩展至古籍插图、书法等视觉材料
2. 评测大模型在古典文化视觉内容上的理解能力
3. 联合发表关于 AI 文化理解的研究论文

不知您是否有兴趣探讨合作？我可以分享完整的数据集和评测方法论。

祝好，

俞昊睿 (February)
VULCA 团队
AI 艺术评测平台
https://vulcaart.art

论文链接：https://aclanthology.org/2025.findings-emnlp.103/
预约演示：https://cal.com/vulcaart/demo
```

---

## 发送跟踪表

| # | 收件人 | 渠道 | 邮箱/链接 | 发送日期 | 状态 | 回复日期 | 备注 |
|---|--------|------|-----------|----------|------|----------|------|
| 1 | 王晋东 | Email | jwang80@wm.edu | 2026-01-25 | ✅ 已发送 | ✅ 已回复 (2026-02-06) | CultureVLM 通讯作者，已视频会议 |
| 2 | 冯雁 | Email | pascale@ust.hk | 2026-01-25 | ✅ 已发送 | | HKUST Chair Prof |
| 3 | Paul Pu Liang | Email | ppliang@mit.edu | 2026-01-25 | ✅ 已发送 | | MIT 新教授 |
| 4 | Yi R. Fung | Email | yrfung@ust.hk | 2026-01-25 | ✅ 已发送 | | HKUST 新教授 |
| 5 | Trevor Darrell | Email | trevor@eecs.berkeley.edu | 2026-01-25 | ✅ 已发送 | | BAIR Co-Director |
| 6 | Val Ravaglia | LinkedIn | linkedin.com/in/val-ravaglia-9b768049/ | | 待发送 | | Tate Modern (需 LinkedIn InMail) |
| 7 | Sarah Schwettmann | Email | sarah@transluce.org | 2026-01-25 | ✅ 已发送 | | MIT/Transluce |
| 8 | Louis-Philippe Morency | Email | morency@cs.cmu.edu | 2026-01-25 | ✅ 已发送 | | CMU MultiComp |
| 9 | British Museum | Email | corporatesupport@britishmuseum.org | 2026-01-25 | ✅ 已发送 | | Corporate Support |
| 10 | 杨浩 | Email | yanghao2008@pku.edu.cn | 2026-01-25 | ✅ 已发送 | | 北大数字人文 |

---

## Follow-up 模板（7 天后使用）

**Subject**: Re: [原邮件主题]

```
Hi [Name],

Following up on my previous email about VULCA - our cultural evaluation benchmark for VLMs.

Quick summary:
- 47 evaluation dimensions across 8 cultural traditions
- L1-L5 hierarchy reveals systematic cultural reasoning gaps
- 15-25% performance difference between Western and non-Western content

Happy to share a sample report if that's more convenient than a call.

Best,
Haorui Yu
VULCA Team
https://vulcaart.art
```

---

*生成于 2026-01-25 by Claude Code*
*遵循 prospect-manager SKILL.md 七步验证流程*
