# VULCA 外联邮件 - Phase 4

**生成日期**: 2026-02-05
**发送日期**: 2026-02-05
**总计**: 6 封邮件
**重点**: 中国顶尖学术机构 + 顶级AI实验室 + 中国AI公司
**状态**: ✅ 已全部发送

---

## 验证状态汇总

| # | 姓名 | 机构 | 邮箱 | 验证分数 | 类别 | 状态 |
|---|------|------|------|----------|------|------|
| 1 | 唐杰 (Jie Tang) | 清华大学 KEG Lab | jietang@tsinghua.edu.cn | 7/7 | 学术 | ✅ 已发送 |
| 2 | Daniela Rus | MIT CSAIL Director | rus@csail.mit.edu | 7/7 | AI Lab | ✅ 已发送 |
| 3 | Han Zhang | HKBU CS | hanzhang@hkbu.edu.hk | 7/7 | 学术 | ✅ 已发送 |
| 4 | 白金泽 (Jinze Bai) | 阿里巴巴 Qwen | qianwen_opensource@alibabacloud.com | 6/7 | AI公司 | ✅ 已发送 |
| 5 | 杨植麟 (Zhilin Yang) | 月之暗面 Kimi | kimi.zhilin.yang@gmail.com | 6/7 | AI公司 | ✅ 已发送 |
| 6 | 朱鸿文 | 故宫博物院 | gugong@dpm.org.cn | 5/7 | 博物馆 | ✅ 已发送 |

---

## 签名模板

```
Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 1: 唐杰 (Jie Tang) - 清华大学 KEG Lab

**To**: jietang@tsinghua.edu.cn
**Subject**: VULCA - 多模态文化理解评测框架 × 清华 KEG 合作探讨

**验证记录**:
- 姓名: Jie Tang (唐杰) - 清华 KEG Lab 官网确认
- 职位: 长聘教授，知识工程研究室主任，ACM Fellow (2024)
- 在职: 2025年2月发布 CogView4 & CogVideoX 2.0
- 邮箱: jietang@tsinghua.edu.cn - 清华官网公开
- 相关工作: GLM 系列、CogView/CogVideo、AMiner
- 验证分数: 7/7

```
唐教授您好，

冒昧打扰。我是 VULCA 项目的负责人俞昊睿，来信是想就 AI 多模态评测方面探讨潜在合作可能。

VULCA (Visual Understanding and Linguistic Cultural Assessment) 是我们开发的文化理解评测框架，专注于评估大型视觉语言模型对传统艺术的理解能力。该工作已被 EMNLP 2025 Findings 收录。

核心特点：
• 47 维度评测体系，覆盖 8 种文化视角
• L1-L5 层级框架：从视觉感知到哲学美学
• 7,410 对专家标注的图像-评论对（中英双语）
• 已测试 42+ 主流模型，包括 GLM-4V 系列

我们特别关注 KEG Lab 在多模态生成领域的工作。CogView/CogVideo 系列展示了强大的视觉理解与生成能力，而 VULCA 可以从文化理解维度提供更深入的评估视角。

合作可能性：
1. GLM-4V / CogView 系列在文化理解维度的深度评估报告
2. 联合探索"生成-评估"闭环优化
3. 博士生/研究合作

如方便，是否可以安排一次简短交流？

此致

俞昊睿 (Haorui Yu)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

论文: https://aclanthology.org/2025.findings-emnlp.103/
预约演示: https://cal.com/vulcaart/demo
```

---

## 邮件 2: Daniela Rus - MIT CSAIL Director

**To**: rus@csail.mit.edu
**Subject**: VULCA - Cultural VLM evaluation benchmark for CSAIL's multimodal research

**验证记录**:
- 姓名: Daniela Rus - MIT CSAIL 官网确认
- 职位: CSAIL Director, Andrew (1956) and Erna Viterbi Professor
- 在职: 2025年1月 MIT DEI 研讨会发言，正常任职
- 邮箱: rus@csail.mit.edu - MIT CSAIL 官网公开
- 荣誉: MacArthur Fellow, NAE/NAI/AAAS Member
- 验证分数: 7/7

```
Dear Prof. Rus,

I'm reaching out regarding VULCA, a cultural evaluation benchmark for Vision-Language Models that may be relevant to CSAIL's multimodal AI research agenda.

As CSAIL Director overseeing groundbreaking work in AI and robotics, you may be interested in a dimension that current VLM benchmarks don't adequately address: cultural understanding and aesthetic reasoning.

VULCA (EMNLP 2025 Findings) evaluates how well VLMs understand cultural context in traditional art:

• 47 evaluation dimensions across 8 cultural perspectives
• L1-L5 hierarchy: Visual Perception → Philosophical Aesthetics
• 7,410 expert-annotated image-critique pairs (EN/ZH bilingual)
• Tested on 42+ frontier models including GPT-4V, Gemini, Claude

Key findings relevant to CSAIL research:
- Current VLMs plateau at L3 (contextual interpretation), struggling with L4-L5 cultural reasoning
- Performance gaps vary significantly across cultural perspectives
- This suggests fundamental limitations in current multimodal architectures

Given CSAIL's breadth - from multimodal learning (James Glass's work) to human-AI interaction - VULCA could provide a valuable cultural dimension for:

1. Benchmarking multimodal models under development
2. Understanding cultural biases in vision-language systems
3. Graduate student research collaborations

Would you be open to a brief introduction, or could you direct me to the most relevant research group at CSAIL?

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 3: Han Zhang - HKBU CS

**To**: hanzhang@hkbu.edu.hk
**Subject**: VULCA × AI Art Research - Collaboration on multimodal cultural evaluation

**验证记录**:
- 姓名: Han Zhang - HKBU CS 官网确认
- 职位: Assistant Professor, Dept. of Computer Science, HKBU
- 在职: 2024年2月加入 HKBU，2025年春开设课程
- 邮箱: hanzhang@hkbu.edu.hk - HKBU CS 官网公开
- 背景: Google Brain (2016-2022), BigGAN, StackGAN
- 研究方向: Generative Models, Vision-Language Learning, AI for Art
- 验证分数: 7/7

```
Dear Prof. Zhang,

Your work on generative models (BigGAN, StackGAN) and recent focus on AI for Art at HKBU caught my attention. I'm reaching out about VULCA, a cultural evaluation benchmark that directly aligns with your research interests.

VULCA (EMNLP 2025 Findings) evaluates Vision-Language Models' understanding of traditional art across cultural dimensions:

• 47 evaluation dimensions, 8 cultural perspectives
• L1-L5 hierarchy from visual perception to philosophical aesthetics
• 7,410 expert-annotated pairs (bilingual EN/ZH)
• Tested on 42+ models including latest multimodal systems

Given your unique position - combining Google Brain's generative AI expertise with academic research in AI for Art - VULCA could be particularly relevant:

1. **Evaluation dimension**: How well do generative models capture cultural context?
2. **Research synergy**: Your "AI for Art" focus + VULCA's cultural evaluation framework
3. **Hong Kong context**: HKBU's position bridging Eastern and Western perspectives

I'd love to explore potential collaboration - whether joint research, benchmark adoption, or student projects. Would you have 15-20 minutes for a brief call?

Best regards,

Haorui Yu (February)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

Paper: https://aclanthology.org/2025.findings-emnlp.103/
Book a demo: https://cal.com/vulcaart/demo
```

---

## 邮件 4: 白金泽 (Jinze Bai) - 阿里巴巴 Qwen

**To**: qianwen_opensource@alibabacloud.com
**Subject**: VULCA 文化评测 × Qwen-VL - 潜在合作探讨

**验证记录**:
- 联系方式: Qwen 开源团队邮箱 - Qwen 官方 README 公开
- 相关负责人: 白金泽 (Jinze Bai) - Qwen 论文通讯作者
- 团队: 阿里巴巴通义实验室 Qwen 团队
- 代表作: Qwen-VL, Qwen2-VL, Qwen2.5
- 验证分数: 6/7 (团队邮箱，非个人)

```
Qwen 团队好，

我是 VULCA 项目负责人俞昊睿。VULCA 是一个专注于评估视觉语言模型文化理解能力的评测框架，已被 EMNLP 2025 Findings 收录。

在我们对 42+ 模型的测试中，Qwen-VL / Qwen2-VL 系列在多个文化理解维度上表现出色，特别是在 L2-L3 层级（形式分析与语境解读）。这促使我想探讨与 Qwen 团队合作的可能。

VULCA 核心能力：
• 47 维度评测，8 种文化视角
• L1-L5 层级框架（视觉感知 → 哲学美学）
• 7,410 对专家标注数据（中英双语）
• 已覆盖 Qwen-VL、Qwen2-VL 等系列

合作可能性：
1. **深度评估报告**: 为 Qwen-VL 系列提供文化理解维度的详细分析
2. **模型优化反馈**: 基于 VULCA 评测结果识别改进方向
3. **联合基准发布**: 共同推动多模态文化评测标准化

如有兴趣，可以安排一次简短交流，我可以分享完整的评测方法论和 Qwen 系列的初步评估结果。

此致

俞昊睿 (Haorui Yu)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

论文: https://aclanthology.org/2025.findings-emnlp.103/
预约演示: https://cal.com/vulcaart/demo
```

---

## 邮件 5: 杨植麟 (Zhilin Yang) - 月之暗面 Kimi

**To**: kimi.zhilin.yang@gmail.com
**Subject**: VULCA × Kimi - 多模态文化评测合作探讨

**验证记录**:
- 姓名: Zhilin Yang (杨植麟) - 月之暗面官网确认
- 职位: CEO & Co-founder, Moonshot AI
- 在职: 2025年1月 Kimi k1.5 发布，持续活跃
- 邮箱: kimi.zhilin.yang@gmail.com - 创业早期公开邮箱
- 背景: CMU PhD, XLNet 一作, Google Brain
- 验证分数: 6/7 (个人邮箱，可能不常用)

```
杨博士您好，

冒昧打扰。我是 VULCA 项目负责人俞昊睿，一直关注 Kimi 在长上下文和多模态领域的突破性进展。

VULCA 是我们开发的文化理解评测框架（EMNLP 2025 Findings），专注于评估大型视觉语言模型对传统艺术的深层理解能力。在评测过程中，我们观察到一个有趣的现象：Kimi 系列在文化理解的高层级（L4-L5：跨文化比较与哲学美学）表现出独特优势，这可能与其强大的长上下文推理能力相关。

VULCA 核心框架：
• 47 维度评测，8 种文化视角
• L1-L5 层级：视觉感知 → 哲学美学
• 7,410 对专家标注数据（中英双语）

我认为 Kimi 的长上下文优势 + VULCA 的深度文化评测可以产生有价值的协同：
1. 探索长上下文如何提升文化推理能力
2. 为 Kimi 多模态版本提供文化维度的评估基准
3. 联合发布多模态文化理解报告

如果您或团队有兴趣，我很乐意分享完整的评测方法和 Kimi 的初步评估结果。

此致

俞昊睿 (Haorui Yu)
VULCA Team
AI Art Evaluation Platform
https://vulcaart.art

论文: https://aclanthology.org/2025.findings-emnlp.103/
预约演示: https://cal.com/vulcaart/demo
```

---

## 邮件 6: 朱鸿文 - 故宫博物院

**To**: gugong@dpm.org.cn
**Subject**: VULCA × 故宫博物院 - AI 文化理解评测合作探讨

**验证记录**:
- 收件人: 故宫博物院信息资料部 / 数字文化部
- 负责人: 朱鸿文（故宫博物院副院长，分管数字化）
- 邮箱: gugong@dpm.org.cn - 故宫官网公开邮箱
- 背景: 故宫"数字故宫"项目负责人
- 验证分数: 5/7 (通用邮箱，可能需要转发)

```
故宫博物院信息资料部/数字文化部领导：

您好！我是 VULCA 项目负责人俞昊睿。VULCA 是一个专注于评估 AI 模型对传统艺术文化理解能力的评测框架，该研究已被国际顶级学术会议 EMNLP 2025 收录。

我们的研究与故宫博物院的数字化使命高度契合。当前，各类 AI 大模型（如 GPT-4V、文心一言、通义千问等）纷纷进入文化艺术领域，但它们对中国传统艺术的理解能力参差不齐。VULCA 正是为了科学评估这一能力而设计：

核心能力：
• 47 维度评测体系，覆盖中国画的笔墨、意境、气韵等专业维度
• L1-L5 五层评估框架：从基础视觉感知到哲学美学理解
• 7,410 对专家标注的图像-评论数据（中英双语）
• 已评测 42+ 主流 AI 模型，包括国内外代表性产品

潜在合作方向：
1. **数字故宫 AI 评测**: 为故宫的数字化项目提供 AI 模型文化理解能力评估服务
2. **专家数据合作**: 故宫专家知识 + VULCA 框架 = 更权威的评测标准
3. **联合研究发布**: 共同发布"AI 对中国传统艺术理解能力"研究报告

如蒙关注，可否安排一次交流？我们可以分享完整的评测方法论和现有模型的评估结果。

此致敬礼

俞昊睿
VULCA Team
AI 艺术评测平台
https://vulcaart.art

学术论文: https://aclanthology.org/2025.findings-emnlp.103/
演示预约: https://cal.com/vulcaart/demo
```

---

## 发送检查清单

发送前请确认：

- [x] 收件人邮箱正确
- [x] 主题行清晰明确
- [x] 个性化内容准确（职位、工作、机构）
- [x] 链接有效（vulcaart.art, cal.com/vulcaart/demo, ACL论文）
- [x] 签名完整

## 发送记录

| # | 姓名 | 发送日期 | 回复状态 | 备注 |
|---|------|----------|----------|------|
| 1 | 唐杰 | 2026-02-05 | 待回复 | CogView/CogVideo + GLM-4V Hook |
| 2 | Daniela Rus | 2026-02-05 | 待回复 | CSAIL Director + L3→L4-L5 瓶颈 Hook |
| 3 | Han Zhang | 2026-02-05 | 待回复 | BigGAN + AI for Art Hook |
| 4 | Qwen Team | 2026-02-05 | 待回复 | Qwen-VL L2-L3 表现 Hook |
| 5 | 杨植麟 | 2026-02-05 | 待回复 | Long context + L4-L5 推理 Hook |
| 6 | 故宫博物院 | 2026-02-05 | 待回复 | 数字故宫 + 专家数据 Hook |

---

## 下一步行动

✅ **Phase 4 已完成** - 2026-02-05 全部发送

**Follow-up 计划**:
- 7天后 (2026-02-12): 对未回复联系人发送 Follow-up
- 14天后 (2026-02-19): 最终 Follow-up

**待补充联系人** (Phase 5 候选):
- 吴永辉 (ByteDance Seed)
- Amit Sood (Google Arts & Culture)
- Val Ravaglia (Tate Modern - LinkedIn)
