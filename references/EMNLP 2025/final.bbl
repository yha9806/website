\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Acker(1954)}]{acker1954some}
William Reynolds~Beal Acker. 1954.
\newblock \emph{Some T'ang and Pre-T'ang Texts on Chinese Painting}.
\newblock Brill.

\bibitem[{Baxandall(1985)}]{baxandall1985patterns}
Michael Baxandall. 1985.
\newblock \emph{Patterns of Intention: On the Historical Explanation of
  Pictures}.
\newblock Yale University Press, New Haven.

\bibitem[{Bin et~al.(2024)Bin, Shi, Ding, Hu, Wang, Yang, Ng, and
  Shen}]{bin_gallerygpt_2024}
Yi~Bin, Wenhao Shi, Yujuan Ding, Zhiqiang Hu, Zheng Wang, Yang Yang, See-Kiong
  Ng, and Heng~Tao Shen. 2024.
\newblock \href {https://arxiv.org/abs/2408.00491} {Gallerygpt: Analyzing
  paintings with large multimodal models}.
\newblock \emph{arXiv preprint arXiv:2408.00491}.

\bibitem[{Bush(1971)}]{bush1971chinese}
Susan Bush. 1971.
\newblock \emph{The Chinese Literati on Painting: Su Shih (1037-1101) to Tung
  Ch'i-ch'ang (1555-1636)}.
\newblock Harvard University Press.

\bibitem[{Cohen(1988)}]{cohen1988statistical}
Jacob Cohen. 1988.
\newblock \emph{Statistical Power Analysis for the Behavioral Sciences}, 2nd
  edition.
\newblock Lawrence Erlbaum Associates, Hillsdale, NJ.

\bibitem[{Fleiss(1971)}]{fleiss1971measuring}
Joseph~L Fleiss. 1971.
\newblock \href {https://doi.org/10.1037/h0031619} {Measuring nominal scale
  agreement among many raters}.
\newblock \emph{Psychological Bulletin}, 76(5):378--382.

\bibitem[{Fu et~al.(2024)Fu, Chen, Shen, Lin, Zhao, Zhang, Zhao, Xie, and
  Qiao}]{fu2023mme}
Chaoyou Fu, Peixian Chen, Yunhao Shen, Yunjie Lin, Shuhuai Zhao, Fangyun Zhang,
  Baobao Zhao, Weizhu Xie, and Yu~Qiao. 2024.
\newblock \href {https://arxiv.org/abs/2306.13394} {Mme: A comprehensive
  evaluation benchmark for multimodal large language models}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 1--10.

\bibitem[{Gombrich(1960)}]{gombrich1960art}
Ernst~H. Gombrich. 1960.
\newblock \emph{Art and Illusion: A Study in the Psychology of Pictorial
  Representation}.
\newblock Princeton University Press, Princeton.

\bibitem[{Guo et~al.(2023)Guo, Jin, Liu, Huang, Shi, Supryadi, Yu, Liu, Li,
  Xiong, and Xiong}]{guo2023evaluating}
Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Supryadi, Linhao Yu,
  Yan Liu, Jiaxuan Li, Bojian Xiong, and Deyi Xiong. 2023.
\newblock \href {https://arxiv.org/abs/2310.19736} {Evaluating large language
  models: A comprehensive survey}.
\newblock \emph{Preprint}, arXiv:2310.19736.

\bibitem[{Hayashi et~al.(2024)Hayashi, Onishi, Suzuki, Ide, Gobara, Saito,
  Sakai, Kamigaito, Hayashi, and Watanabe}]{hayashi_irr_2024}
Kazuki Hayashi, Kazuma Onishi, Toma Suzuki, Yusuke Ide, Seiji Gobara, Shigeki
  Saito, Yusuke Sakai, Hidetaka Kamigaito, Katsuhiko Hayashi, and Taro
  Watanabe. 2024.
\newblock \href {https://arxiv.org/abs/2402.12121} {Irr: Image review ranking
  framework for evaluating vision-language models}.
\newblock \emph{arXiv preprint arXiv:2402.12121}.

\bibitem[{{International Council of Museums}(2022)}]{icom_cidoc_standards}
{International Council of Museums}. 2022.
\newblock \href
  {https://cidoc.mini.icom.museum/standards/cidoc-standards-guidelines/} {Cidoc
  standards guidelines}.
\newblock Accessed: 2024.

\bibitem[{Jiang et~al.(2024)Jiang, Zhang, Cao, Breazeal, Roy, and
  Kabbara}]{jiang2024personallm}
Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal, Deb Roy, and Jad Kabbara.
  2024.
\newblock \href {https://arxiv.org/abs/2305.02547} {Personallm: Investigating
  the ability of large language models to express personality traits}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  NAACL 2024}, pages 3011--3030.

\bibitem[{Jiang and Chen(2025)}]{jiang_multimodal_2025}
Ruixiang Jiang and Changwen Chen. 2025.
\newblock \href {https://arxiv.org/abs/2501.09012} {Multimodal llms can reason
  about aesthetics in zero-shot}.
\newblock \emph{arXiv preprint arXiv:2501.09012}.

\bibitem[{Krishna et~al.(2017)Krishna, Zhu, Groth, Johnson, Hata, Kravitz,
  Chen, Kalantidis, Li, Shamma, Bernstein, and Li}]{krishna2017visual}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua
  Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A. Shamma,
  Michael~S. Bernstein, and Fei-Fei Li. 2017.
\newblock \href {https://arxiv.org/abs/1602.07332} {Visual genome: Connecting
  language and vision using crowdsourced dense image annotations}.
\newblock \emph{Preprint}, arXiv:1602.07332.

\bibitem[{Lewis et~al.(2020)Lewis, Liu, Goyal, Ghazvininejad, Mohamed, Levy,
  Stoyanov, and Zettlemoyer}]{lewis2020bart}
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
  Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.703} {Bart:
  Denoising sequence-to-sequence pre-training for natural language generation,
  translation, and comprehension}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 7871--7880.

\bibitem[{Li et~al.(2024)Li, Wang, Wang, Ge, Ge, and Shan}]{li_seed-bench_2023}
Bohao Li, Rui Wang, Guangzhi Wang, Yuying Ge, Yixiao Ge, and Ying Shan. 2024.
\newblock \href {https://arxiv.org/abs/2307.16125} {Seed-bench: Benchmarking
  multimodal llms with generative comprehension}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 13299--13308.

\bibitem[{Lin et~al.(2014)Lin, Maire, Belongie, Bourdev, Girshick, Hays,
  Perona, Ramanan, Zitnick, and Doll{\'a}r}]{Lin2014MicrosoftCC}
Tsung-Yi Lin, Michael Maire, Serge~J. Belongie, Lubomir~D. Bourdev, Ross~B.
  Girshick, James Hays, Pietro Perona, Deva Ramanan, C.~Lawrence Zitnick, and
  Piotr Doll{\'a}r. 2014.
\newblock \href {https://arxiv.org/abs/1405.0312} {Microsoft coco: Common
  objects in context}.
\newblock \emph{ArXiv}, abs/1405.0312.

\bibitem[{Liu et~al.(2023)Liu, Li, Wu, and Lee}]{liu_visual_2023}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee. 2023.
\newblock \href
  {https://proceedings.neurips.cc/paper_files/paper/2023/file/6dcf277ea32ce3288914faf369fe6de0-Paper-Conference.pdf}
  {Visual {Instruction} {Tuning}}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  volume~36, pages 34892--34916. Curran Associates, Inc.

\bibitem[{Liu et~al.(2024)Liu, Duan, Zhang, Li, Zhang, Zhao, Yuan, Wang, He,
  Liu, Chen, and Lin}]{liu2024mmbench}
Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo~Li, Songyang Zhang, Wangbo Zhao, Yike
  Yuan, Jiaqi Wang, Conghui He, Ziwei Liu, Kai Chen, and Dahua Lin. 2024.
\newblock \href {https://arxiv.org/abs/2307.06281} {Mmbench: Is your
  multi-modal model an all-around player?}
\newblock In \emph{Computer Vision--ECCV 2024}, pages 216--233. Springer.

\bibitem[{Nayak et~al.(2024)Nayak, Jain, Awal, Reddy, Tayyar~Madabushi,
  Ganeriwal, Mamidi, and Kocielnik}]{nayak2024benchmarking}
Shravan Nayak, Kanishk Jain, Rabiul Awal, Siva Reddy, Harish Tayyar~Madabushi,
  Suman Ganeriwal, Radhika Mamidi, and Rafal Kocielnik. 2024.
\newblock \href {https://arxiv.org/abs/2407.10920} {Benchmarking vision
  language models for cultural understanding}.
\newblock In \emph{arXiv preprint arXiv:2407.10920}.

\bibitem[{Panofsky(1955)}]{panofsky1955meaning}
Erwin Panofsky. 1955.
\newblock \emph{Meaning in the Visual Arts}.
\newblock Doubleday.

\bibitem[{Shanahan et~al.(2023)Shanahan, McDonell, and
  Reynolds}]{shanahan_role_play_2023}
Murray Shanahan, Kyle McDonell, and Laria Reynolds. 2023.
\newblock \href {https://www.nature.com/articles/s41586-023-06647-8} {Role play
  with large language models}.
\newblock \emph{Nature}, 623(7987):493--498.

\bibitem[{Shrout and Fleiss(1979)}]{shrout1979intraclass}
Patrick~E Shrout and Joseph~L Fleiss. 1979.
\newblock \href {https://doi.org/10.1037/0033-2909.86.2.420} {Intraclass
  correlations: uses in assessing rater reliability}.
\newblock \emph{Psychological Bulletin}, 86(2):420--428.

\bibitem[{Sir{\'e}n(1936)}]{siren1936chinese}
Osvald Sir{\'e}n. 1936.
\newblock \emph{The Chinese on the Art of Painting: Texts by the
  Painter-Critics, from the Han through the Ch'ing Dynasties}.
\newblock Peiping: Henri Vetch.

\bibitem[{{The Metropolitan Museum of Art}(2021)}]{met_museum_standards}
{The Metropolitan Museum of Art}. 2021.
\newblock \href
  {http://files.archivists.org/groups/museum/standards/10-MMA_Archives_Processing_and_cataloging_Manual.pdf}
  {Archives processing and cataloging manual}.
\newblock Technical report, The Metropolitan Museum of Art Archives.

\bibitem[{van~der Maaten and Hinton(2008)}]{van2008visualizing}
Laurens van~der Maaten and Geoffrey Hinton. 2008.
\newblock \href {https://www.jmlr.org/papers/v9/vandermaaten08a.html}
  {Visualizing data using t-sne}.
\newblock \emph{Journal of Machine Learning Research}, 9(86):2579--2605.

\bibitem[{Wang(2024)}]{wang_changes_2024}
Yuhan Wang. 2024.
\newblock \href {https://doi.org/10.4236/oalib.1111427} {The {Changes} of
  "{Shen}" and "{Yi}" in {Chinese} {Painting} {Aesthetics}: {From} {Gu}
  {Kaizhi} to {Ni} {Zan}}.
\newblock \emph{Open Access Library Journal}, 11(4):1--6.

\bibitem[{Wang et~al.(2024)Wang, Peng, Que, Liu, Zhou, Wu, Guo, Gan, Ni, Zhang,
  Zhang, Ouyang, Xu, Huang, Fu, and Peng}]{wang_rolellm_2024}
Zekun~Moore Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou,
  Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Man Zhang, Zhaoxiang Zhang,
  Wanli Ouyang, Ke~Xu, Wenhu~Chen Huang, Jie Fu, and Junran Peng. 2024.
\newblock \href {https://arxiv.org/abs/2310.00746} {{RoleLLM}: {Benchmarking},
  {Eliciting}, and {Enhancing} {Role}-{Playing} {Abilities} of {Large}
  {Language} {Models}}.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 13989--14008.

\bibitem[{Williams et~al.(2018)Williams, Nangia, and
  Bowman}]{williams2018broad}
Adina Williams, Nikita Nangia, and Samuel Bowman. 2018.
\newblock \href {https://doi.org/10.18653/v1/N18-1101} {A broad-coverage
  challenge corpus for sentence understanding through inference}.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 1112--1122.

\bibitem[{W{\"o}lfflin(1950)}]{wolfflin1950principles}
Heinrich W{\"o}lfflin. 1950.
\newblock \emph{Principles of Art History: The Problem of the Development of
  Style in Later Art}.
\newblock Dover Publications.

\bibitem[{Xiao et~al.(2024)Xiao, Liu, Zhang, Muennighoff, Lian, and
  Nie}]{xiao2023cpack}
Shitao Xiao, Zheng Liu, Peitian Zhang, Niklas Muennighoff, Defu Lian, and
  Jian-Yun Nie. 2024.
\newblock \href {https://doi.org/10.1145/3626772.3657878} {C-pack: Packaged
  resources to advance general chinese embedding}.
\newblock In \emph{Proceedings of the 47th International ACM SIGIR Conference
  on Research and Development in Information Retrieval}, pages 1316--1327.
\newblock Also available as arXiv:2309.07597.

\bibitem[{Xie(550)}]{xie_he_six_canons}
He~Xie. 550.
\newblock \emph{Guhua Pinlu [The Record of the Classification of Old
  Painters]}.
\newblock [Manuscript], China.
\newblock Original text circa 550 CE. English translation in: Bush, Susan and
  Hsio-yen Shih. Early Chinese Texts on Painting. Cambridge: Harvard University
  Press, 1985, pp. 39-41.

\bibitem[{You et~al.(2023)You, Zhang, Gan, Du, Zhang, Wang, Cao, Chang, and
  Yang}]{you2023ferret}
Haoxuan You, Haotian Zhang, Zhe Gan, Xianzhi Du, Bowen Zhang, Zirui Wang,
  Liangliang Cao, Shih-Fu Chang, and Yinfei Yang. 2023.
\newblock \href {https://arxiv.org/abs/2310.07704} {Ferret: Refer and ground
  anything anywhere at any granularity}.
\newblock \emph{Preprint}, arXiv:2310.07704.

\bibitem[{Yuan et~al.(2024)Yuan, Xue, Wang, Liu, Zhao, and
  Wang}]{chen2023artgpt}
Zhengqing Yuan, Huiwen Xue, Xinyi Wang, Yongming Liu, Zhuanzhe Zhao, and Kun
  Wang. 2024.
\newblock Artgpt-4: Artistic vision-language understanding with
  adapter-enhanced mllm.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 1--10.

\bibitem[{Zhang et~al.(2024{\natexlab{a}})Zhang, Feng, Ni, Cao, Liu, Butler,
  Weng, Zhang, Narayanan, and Avestimehr}]{zhang_creating_2024}
Tuo Zhang, Tiantian Feng, Yibin Ni, Mengqin Cao, Ruying Liu, Katharine Butler,
  Yanjun Weng, Mi~Zhang, Shrikanth~S. Narayanan, and Salman Avestimehr.
  2024{\natexlab{a}}.
\newblock \href {https://arxiv.org/abs/2406.10318} {Creating a lens of chinese
  culture: A multimodal dataset for chinese pun rebus art understanding}.
\newblock \emph{arXiv preprint arXiv:2406.10318}.

\bibitem[{Zhang et~al.(2024{\natexlab{b}})Zhang, Kam-Kwai, Xu, Ren, Li, Zhu,
  Feng, and Chen}]{zhang_cultiverse_2024}
Wei Zhang, Wong Kam-Kwai, Biying Xu, Yiwen Ren, Yuhuai Li, Minfeng Zhu,
  Yingchaojie Feng, and Wei Chen. 2024{\natexlab{b}}.
\newblock \href {https://arxiv.org/abs/2405.00435} {Cultiverse: Towards
  cross-cultural understanding for paintings with large language model}.
\newblock \emph{arXiv preprint arXiv:2405.00435}.

\bibitem[{Zhang et~al.(2023)Zhang, Aljunied, Gao, Chia, and
  Bing}]{zhang_m3exam_2023}
Wenxuan Zhang, Sharifah~Mahani Aljunied, Chang Gao, Yew~Ken Chia, and Lidong
  Bing. 2023.
\newblock \href {https://arxiv.org/abs/2306.05179} {M3exam: A multilingual,
  multimodal, multilevel benchmark for examining large language models}.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}.

\end{thebibliography}
