\section{Experimental Setup Details}
\label{app:setup}

\subsection{Automated Data Processing and Analysis Workflow}
\label{app:automated_workflow}
The quantitative analysis in this research is supported by a series of automated scripts. The workflow is divided into three main phases:

\subsubsection{Phase 1: Feature Extraction from Human Expert Texts}
\label{sub:script_extract_features}
\begingroup\sloppy
This phase is handled by an automated script.
\fussy\endgroup
\begin{itemize}
    \item \textbf{Purpose:} To automatically extract predefined textual features from a collection of human expert commentaries on Chinese art. These features include evaluative stances, core analytical focal points (such as "Use of Color", "Artistic Conception"), and argumentative quality aspects (such as "Profound Insight", "Clear Logic").
    \item \textbf{Input:}
    \begin{itemize}
        \item A base directory containing \texttt{.txt} files of human expert critiques.
        \item Predefined lists of English candidate labels for stance, features, and quality (as listed in Appendix~\ref{app:zeroshot_labels}), along with their Chinese translations used internally for reporting if needed.
    \end{itemize}
    \item \textbf{Key Processing Steps:}
    \begin{enumerate}
        \item Recursively scans the input directory for all \texttt{.txt} files.
        \item \begingroup\sloppy Loads a zero-shot classification model.\fussy\endgroup
        \item For each critique text:
        \begin{itemize}
            \item \begingroup\sloppy Predicts the primary evaluative stance (single-label classification from the stance label set).\fussy\endgroup
            \item Predicts multiple core focal points (multi-label classification from the feature label set).
            \item Predicts multiple argumentative quality features (multi-label classification from the quality label set).
        \end{itemize}
        \item Stores the determined English label and its confidence score for the primary stance.
        \item Stores the English labels and confidence scores for all identified features and quality aspects. These are typically stored as dictionary-like structures mapping the label to its score.
    \end{enumerate}
    \item \textbf{Outputs:}
    \begin{itemize}[itemsep=1pt]
        \item A consolidated master CSV file where each row represents a critique: a unique \texttt{file\_id}, a \texttt{text\_preview}, the predicted stance and its score, all predicted focal points and their scores, and all predicted quality features and their scores.
        \item Individual CSV files for each scholar/work (derived from sub-directory names), containing the same information for critiques within that specific scope.
    \end{itemize}
\end{itemize}

\subsubsection{Phase 2: Exploratory Data Analysis and Feature Visualization of Human and MLLM Data}
\label{sub:script_eda_viz}
\begingroup\sloppy
This phase is handled by an automated script.
\fussy\endgroup
\begin{itemize}
    \item \textbf{Purpose:} To perform exploratory data analysis (EDA) on the extracted features from both human experts (output from Phase 1) and a baseline MLLM, and to visualize the combined feature space using dimensionality reduction.
    \item \textbf{Input:}
    \begin{itemize}
        \item The consolidated human expert features CSV from Phase 1.
        \item \begingroup\sloppy A consolidated MLLM features CSV, assumed to have a compatible structure, particularly for 'features' and 'quality' columns.\fussy\endgroup
    \end{itemize}
    \item \textbf{Key Processing Steps:}
    \begin{enumerate}
        \item \begingroup\sloppy Loads and combines the human and MLLM feature data, adding a \texttt{source\_type} column to differentiate origins.\fussy\endgroup
        \item Parses stringified 'features' and 'quality' columns (if stored as strings in CSV) back into dictionary objects.
        \item \begingroup\sloppy Performs EDA, including:\fussy\endgroup
        \begin{itemize}
            \item \begingroup\sloppy Calculating distributions for predicted stances and source types.\fussy\endgroup
            \item For each identified feature and quality item: calculating overall mention counts, mention frequency within comments that have such data, and descriptive statistics (mean, median, std dev, min, max) of their scores across all relevant texts.
        \end{itemize}
        \item Constructs unified feature vectors for each commentary by concatenating all individual feature and quality scores.
        \item Applies t-SNE (t-distributed Stochastic Neighbor Embedding) and UMAP (Uniform Manifold Approximation and Projection, if the library is available) to reduce the dimensionality of these feature vectors to 2D for visualization.
    \end{enumerate}
    \item \textbf{Output:}
    \begin{itemize}
        \item \begingroup\sloppy An EDA summary CSV file detailing the statistical findings from the EDA.\fussy\endgroup
        \item \begingroup\sloppy A CSV file containing the 2D coordinates (x, y) from t-SNE and UMAP for each commentary, along with \texttt{file\_id} and \texttt{source\_type}.\fussy\endgroup
        \item \begingroup\sloppy PNG image files for the t-SNE plot and UMAP plot of the combined feature space, typically colored by stance or source type.\fussy\endgroup
    \end{itemize}
\end{itemize}

\subsubsection{Phase 3: Profile Scoring, Candidate Selection, and Advanced Visualization on Human and MLLM Data}
\label{sub:script_profile_scoring}
\begingroup\sloppy
This phase is handled by an automated script.
\fussy\endgroup
\begin{itemize}
    \item \textbf{Purpose:} To apply a more sophisticated analytical layer by scoring texts against predefined expert profiles, performing dimensionality reduction on these profile scores, calculating profile proportions, and preparing a rich dataset for composite visualizations. This phase also focuses on comparing human expert data with MLLM data.
    \item \textbf{Input:}
    \begin{itemize}
        \item The consolidated human expert features CSV from Phase 1.
        \item \begingroup\sloppy The consolidated MLLM features CSV.\fussy\endgroup
        \item Predefined criteria for "Specialized Micro Profiles" (such as "Comprehensive Analyst," "Historically Focused") and "General Descriptive Profiles." These profiles are defined by rules that consider stance labels, specific feature scores (e.g., "Historical Context" score > 0.5), and quality scores.
    \end{itemize}
    \item \textbf{Key Processing Steps:}
    \begin{enumerate}
        \item Loads and combines human and MLLM feature data, performing necessary preprocessing like parsing feature/quality dictionaries.
        \item \begingroup\sloppy For each text, calculates a match score (typically 0-1) against each predefined expert profile. This involves:\fussy\endgroup
        \begin{itemize}
            \item Checking if a primary stance requirement is met.
            \item \begingroup\sloppy Evaluating if a minimum number of flexible rules (based on feature/quality score thresholds) are satisfied.\fussy\endgroup
            \item Combining these into an overall profile match score, potentially with weighting for stance and feature contributions. Specialized logic is used for "Comprehensive Analyst" and "General Descriptive Profile."
        \end{itemize}
        \item \begingroup\sloppy These profile scores are added as new columns to the dataset.\fussy\endgroup
        \item Constructs new feature vectors based on these profile scores (and potentially other \texttt{score\_*} columns).
        \item Applies t-SNE and UMAP for 2D visualization of these profile-score-based vectors.
        \item \begingroup\sloppy Calculates the proportional contribution of each specialized profile score to the sum of all specialized profile scores for a given text. Determines a primary profile based on the highest proportion.\fussy\endgroup
    \end{enumerate}
    \item \textbf{Output:}
    \begin{itemize}
        \item \begingroup\sloppy A primary CSV file designed for external visualization tools. This includes \texttt{file\_id}, text previews, original profile status, source type, t-SNE/UMAP coordinates derived from profile scores, original filenames, all profile score columns, and the calculated profile proportion columns.\fussy\endgroup
        \item \begingroup\sloppy A secondary, more comprehensive CSV file containing the entire processed dataframe with all original and derived columns, including the profile-based dimensionality reduction coordinates.\fussy\endgroup
    \end{itemize}
\end{itemize}

% User should carefully review the 'Supplementary Quantitative Results' (app:results) section
% to ensure tables and figures align with the outputs of these automated scripts and main paper discussions.



\section{Inter-Annotator Agreement Calculation Details}
\label{app:iaa_calculation}

\subsection{Metrics Definition}

\textbf{Fleiss' Kappa for Multiple Raters.} For categorical labels (e.g., stance categories), we use Fleiss' kappa to measure agreement among multiple annotators beyond chance:

\begin{equation}
\kappa = \frac{\bar{P} - P_e}{1 - P_e}
\end{equation}

where $\bar{P}$ is the mean proportion of rater pairs in agreement, and $P_e$ is the proportion of agreement expected by chance. For $n$ items, $k$ categories, and $N$ raters:

\begin{equation}
\bar{P} = \frac{1}{n} \sum_{i=1}^{n} \frac{1}{N(N-1)} \sum_{j=1}^{k} n_{ij}(n_{ij}-1)
\end{equation}

\begin{equation}
P_e = \sum_{j=1}^{k} p_j^2, \quad p_j = \frac{1}{nN} \sum_{i=1}^{n} n_{ij}
\end{equation}

\textbf{Intraclass Correlation Coefficient (ICC).} For continuous scores (0-1 scale feature prominence), we use ICC(2,1) to assess consistency:

\begin{equation}
\text{ICC}(2,1) = \frac{\text{MS}_B - \text{MS}_W}{\text{MS}_B + (k-1)\text{MS}_W}
\end{equation}

where $\text{MS}_B$ is between-subject mean square, $\text{MS}_W$ is within-subject mean square, and $k$ is the number of raters.

\subsection{Calculation Implementation}

Our IAA calculation uses Fleiss' kappa for multiple raters. Algorithm~\ref{alg:fleiss_kappa} presents the implementation details:

\begin{algorithm}[ht]
\caption{Fleiss' Kappa Calculation for Multiple Raters}
\label{alg:fleiss_kappa}
\begin{algorithmic}[1]
\Require Ratings matrix $R \in \mathbb{R}^{n \times k}$ where $n$ is number of items, $k$ is number of categories
\Ensure Fleiss' kappa coefficient $\kappa \in [-1, 1]$
\State $n, k \gets \text{shape}(R)$
\State $N \gets \sum_{j=1}^{k} R_{1,j}$ \Comment{Number of raters}
\State \textbf{Calculate proportion of agreeing rater pairs:}
\For{$i = 1$ to $n$}
    \State $P_i \gets \frac{\sum_{j=1}^{k} R_{i,j}^2 - N}{N(N-1)}$
\EndFor
\State $\bar{P} \gets \frac{1}{n}\sum_{i=1}^{n} P_i$ \Comment{Mean proportion}
\State \textbf{Calculate chance agreement:}
\For{$j = 1$ to $k$}
    \State $p_j \gets \frac{\sum_{i=1}^{n} R_{i,j}}{nN}$
\EndFor
\State $P_e \gets \sum_{j=1}^{k} p_j^2$ \Comment{Chance agreement}
\State \Return $\kappa = \frac{\bar{P} - P_e}{1 - P_e}$
\end{algorithmic}
\end{algorithm}

The algorithm computes the proportion of agreeing rater pairs ($P_i$) for each item and derives the overall agreement beyond chance. The complete Python implementation is available in our supplementary materials.

\subsection{Interpretation Guidelines}

Following Landis and Koch (1977), we interpret kappa values as:
\begin{itemize}
    \item $<$ 0.00: Poor agreement
    \item 0.00-0.20: Slight agreement
    \item 0.21-0.40: Fair agreement
    \item 0.41-0.60: Moderate agreement
    \item 0.61-0.80: Substantial agreement
    \item 0.81-1.00: Almost perfect agreement
\end{itemize}

For ICC values, we follow Cicchetti (1994):
\begin{itemize}
    \item $<$ 0.40: Poor reliability
    \item 0.40-0.59: Fair reliability
    \item 0.60-0.74: Good reliability
    \item 0.75-1.00: Excellent reliability
\end{itemize}




\section{Annotation Guidelines Extract}
\label{app:annotation_guidelines}

\subsection{Key Label Judgment Criteria}

\begin{table}[ht]
\centering
\footnotesize
\caption{Sample Annotation Criteria for Selected Labels}
\label{tab:annotation_criteria}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{3cm}p{8cm}}
\toprule
\textbf{Label} & \textbf{Judgment Criteria} \\
\midrule
Historical Research & Commentary primarily focuses on historical context, dating, attribution, or provenance. References specific historical events, periods, or figures. \\
\midrule
Aesthetic Appreciation & Emphasizes beauty, emotional response, or artistic merit. Uses evaluative language about visual appeal or expressive power. \\
\midrule
Brushwork Technique & Discusses specific brush techniques, stroke quality, or ink application methods. May reference traditional categories like "broken ink" or "flying white". \\
\midrule
Profound Insight & Offers original interpretation beyond surface observation. Connects artwork to broader cultural, philosophical, or theoretical frameworks. \\
\midrule
Clear Logic & Arguments follow sequential reasoning with explicit connections between claims and evidence. Transitions clearly marked. \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsection{Boundary Cases and Resolution}

When a commentary exhibits characteristics of multiple stance categories:
\begin{enumerate}
    \item Primary stance determined by dominant focus (>50\% of content)
    \item If balanced, consider opening and closing paragraphs as decisive
    \item When technical analysis serves aesthetic appreciation, classify as Aesthetic
    \item Historical context as supporting evidence does not override primary analytical focus
\end{enumerate}

\section{Model Details for Multi-Model Comparative Evaluation}

This section provides detailed information on the models included in the multi-model comparative evaluation, including architecture, parameter count, modality support, context length, knowledge cutoff, licensing, and access method. Detailed specifications for each evaluated model are provided in Table~\ref{tab:model_details_appendix}.

\begin{table*}[htbp]
\centering
\caption{Detailed Specifications of Evaluated Models (Corresponds to Table 1 in `list.md` outline)}
\label{tab:model_details_appendix}
\footnotesize
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccccccc}
\toprule
Model & Parameters & Architecture & Modality & Context Length & Knowledge Cutoff & License & Access \\
\midrule
Gemini 2.5 Pro & Proprietary & Proprietary (Google) & Text, Image, Code & 1M+ & 2024 & Commercial & API (Google Cloud) \\
Llama-3.1-8B-Instruct & 8B & Transformer & Text & 128K & Dec 2023 & Llama 3.1 Community & Open Weights (Meta, HF) \\
Llama-4-Scout-17B-16E-Instruct & 17B (MoE, 16 experts) & MoE Transformer & Text, Image, Code & 10M & Aug 2024 & Llama 4 Community & Open Weights (Meta, HF) \\
Qwen-2.5-VL-7B & 7B & Transformer & Text, Image, Video & 32K+ & 2025 & Apache 2.0 & Open Weights (Alibaba, HF) \\
\bottomrule
\end{tabular}%
}
\end{table*}

\paragraph{Notes:}
\begin{itemize}
    \item \textbf{Gemini 2.5 Pro:} Google proprietary model, supports multimodal input (text, image, code), commercial API only, knowledge cutoff 2024.
    \item \textbf{Llama-3.1-8B-Instruct:} Open-source, text-only, 8B parameters, 128K context, supports 8+ languages, weights available on Meta and Hugging Face.
    \item \textbf{Llama-4-Scout-17B-16E-Instruct:} Open-source, natively multimodal (text, image, code), 17B activated parameters (MoE, 16 experts, 109B total), 10M context, 12 languages, weights on Meta/HF, knowledge cutoff Aug 2024.
    \item \textbf{Qwen-2.5-VL-7B:} Open-source, supports text, image, video, 7B parameters, 32K+ context, 12+ languages, Apache 2.0 license, weights on Alibaba/HF, knowledge cutoff 2025.
\end{itemize}

For further details on model usage, inference settings, and prompt templates, see the main text and project documentation.

\section{Representative Output Samples}
\label{app:output_samples}

\begin{table*}[htbp] % Changed from table[ht] to table*}[htbp]
\centering
\caption{Representative VLM Output Samples with Feature Scores. Fields: Commentary Preview, Stance Label, Feature Scores (excerpt), Quality Assessment (excerpt). Shows differences between basic prompts and persona-guided prompts (Mama Zola, Okakura Kakuzō).}
\label{tab:representative_VLM_samples}
\fontsize{7pt}{10pt}\selectfont % 减小字体大小
\resizebox{\textwidth}{!}{
\begin{tabular}{|p{0.15\textwidth}|p{0.28\textwidth}|p{0.15\textwidth}|p{0.2\textwidth}|p{0.2\textwidth}|} % Adjusted widths to be relative
\hline
\rule{0pt}{3ex}File ID & Commentary Preview & Stance Label & Feature Scores (excerpt) & Quality Assessment (excerpt) \\
\hline
\rule{0pt}{3ex}\seqsplit{April\\四月(basic).txt} & This artwork, evidently a section from the "Fourth Month"... & Socio-cultural Interpretation & Brushwork: 0.99; Layout: 0.98; Line: 0.93... & Logical Gaps: 0.58; Strong Argumentation: 0.50... \\
\hline
\rule{0pt}{3ex}\seqsplit{August\\八月(basic).txt} & This analysis delves into a magnificent example of Qing Dynasty court painting... & Comparative Analysis & Line: 0.90; Layout: 0.90; Spatial: 0.78... & Detailed Analysis: 0.59; Lacks Examples: 0.44... \\
\hline
\rule{0pt}{3ex}\seqsplit{December\\十二月(basic).txt} & This magnificent scroll, a segment from the "Twelve Months Paintings"... & Socio-cultural Interpretation & Brushwork: 0.99; Cross-cultural: 0.98; Layout: 0.98... & Subjective/Biased: 0.89; Logical Gaps: 0.74... \\
\hline
\rule{0pt}{3ex}\seqsplit{April\\四月(with_Mama_Zola).txt} & 从这幅《四月令图》中，我们可见郎世宁融合中西方画法的独特成就... (如果这里提及了Li Ruoyun，则改为Mama Zola) & Historical Research & Historical Context: 0.96; Brushwork: 0.92; Cross-cultural: 0.87... & Classical Citations: 0.78; Profound Insight: 0.62... \\
\hline
\rule{0pt}{3ex}\seqsplit{May\\五月(with_Okakura_Kakuzo).txt} & 此《五月令图》乃郎世宁为乾隆皇帝所作，笔法精妙，构图宏大... (如果这里提及了Dong Qichang，则改为Okakura Kakuzō) & Aesthetic Appreciation & Brushwork: 0.95; Style/School: 0.88; Historical Context: 0.85... & Classical Citations: 0.82; Strong Argumentation: 0.55... \\
\hline
\end{tabular}
} % End of resizebox
\end{table*}

The examples in Table~\ref{tab:representative_VLM_samples} demonstrate the differences in content generated by VLMs under basic prompts versus different persona prompts. Through comparison, we can observe:
1. **Basic Prompt Outputs**: Without persona guidance, models tend to generate more generalized, descriptive content, primarily focusing on visible elements in the image, and often exhibit quality issues such as Logical Gaps and Subjective/Biased assessments.
2. **Chinese Artist Persona Outputs**: Under the guidance of personas like Mama Zola and Okakura Kakuzō, the output content demonstrates stronger historical research tendencies and aesthetic appreciation capabilities, with significantly higher Classical Citations scores and better performance on features such as Historical Context.
3. **Language and Style Differences**: Outputs guided by Chinese personas often begin in Chinese, use more professional terminology, and reference classical literature more frequently, which is closely related to the relevant knowledge points contained in the persona knowledge base.

Further analysis reveals a significant shift in semantic space under different persona guidance, validating the substantial impact of persona intervention on model output characteristics.

