"""
æ¸…ç†ç”Ÿäº§ç¯å¢ƒçš„Mockæ¨¡å‹æ•°æ®
åªä¿ç•™benchmarkæ•°æ®æºçš„æ¨¡å‹
"""
import asyncio
import aiohttp
import json
import sys
import io
from typing import Dict, Any, List

# è®¾ç½®UTF-8ç¼–ç 
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

class MockModelCleaner:
    def __init__(self):
        self.api_url = 'https://wenxin-moyun-api-229980166599.asia-east1.run.app/api/v1'
        self.token = None
        
    async def login(self):
        """ç™»å½•è·å–token"""
        try:
            print("ğŸ” ç™»å½•adminè´¦å·...")
            async with aiohttp.ClientSession() as session:
                # ä½¿ç”¨form-dataæ ¼å¼
                form_data = aiohttp.FormData()
                form_data.add_field('username', 'admin')
                form_data.add_field('password', 'admin123')
                
                async with session.post(
                    f'{self.api_url}/auth/login',
                    data=form_data
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        self.token = data.get('access_token')
                        print(f"âœ… ç™»å½•æˆåŠŸ")
                        return True
                    else:
                        text = await resp.text()
                        print(f"âŒ ç™»å½•å¤±è´¥: {resp.status} - {text}")
                        return False
        except Exception as e:
            print(f"âŒ ç™»å½•é”™è¯¯: {e}")
            return False
    
    async def get_all_models(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ¨¡å‹åˆ—è¡¨"""
        try:
            print("\nğŸ“‹ è·å–æ‰€æœ‰æ¨¡å‹åˆ—è¡¨...")
            async with aiohttp.ClientSession() as session:
                headers = {}
                if self.token:
                    headers['Authorization'] = f'Bearer {self.token}'
                    
                async with session.get(
                    f'{self.api_url}/models',
                    headers=headers
                ) as resp:
                    if resp.status == 200:
                        models = await resp.json()
                        print(f"  æ‰¾åˆ°æ€»è®¡ {len(models)} ä¸ªæ¨¡å‹")
                        return models
                    else:
                        print(f"  è·å–å¤±è´¥: {resp.status}")
                        return []
        except Exception as e:
            print(f"âŒ è·å–æ¨¡å‹é”™è¯¯: {e}")
            return []
    
    async def delete_model(self, model_id: str) -> bool:
        """åˆ é™¤å•ä¸ªæ¨¡å‹"""
        try:
            async with aiohttp.ClientSession() as session:
                headers = {'Authorization': f'Bearer {self.token}'}
                
                async with session.delete(
                    f'{self.api_url}/models/{model_id}',
                    headers=headers
                ) as resp:
                    return resp.status in [200, 204]
        except:
            return False
    
    async def clean_mock_models(self):
        """æ¸…ç†æ‰€æœ‰mockæ¨¡å‹ï¼Œåªä¿ç•™benchmarkæ¨¡å‹"""
        try:
            # è·å–æ‰€æœ‰æ¨¡å‹
            all_models = await self.get_all_models()
            
            # åˆ†ç±»æ¨¡å‹
            benchmark_models = []
            mock_models = []
            
            for model in all_models:
                if model.get('data_source') == 'benchmark':
                    benchmark_models.append(model)
                else:
                    mock_models.append(model)
            
            print(f"\nğŸ“Š æ¨¡å‹åˆ†æ:")
            print(f"  Benchmarkæ¨¡å‹: {len(benchmark_models)} ä¸ª")
            print(f"  Mockæ¨¡å‹: {len(mock_models)} ä¸ª")
            
            if benchmark_models:
                print("\nâœ… Benchmarkæ¨¡å‹åˆ—è¡¨ï¼ˆå°†ä¿ç•™ï¼‰:")
                for i, model in enumerate(benchmark_models[:5], 1):
                    score = model.get('overall_score', 0)
                    if score is None:
                        score = 0
                    print(f"  {i}. {model['name']} ({model['organization']}): {score:.1f}åˆ†")
                if len(benchmark_models) > 5:
                    print(f"  ... è¿˜æœ‰ {len(benchmark_models) - 5} ä¸ª")
            
            if mock_models:
                print(f"\nğŸ—‘ï¸ å‡†å¤‡åˆ é™¤ {len(mock_models)} ä¸ªMockæ¨¡å‹...")
                
                # æ˜¾ç¤ºå°†è¦åˆ é™¤çš„æ¨¡å‹
                print("  å°†åˆ é™¤çš„Mockæ¨¡å‹:")
                for i, model in enumerate(mock_models[:5], 1):
                    score = model.get('overall_score', 0)
                    if score is None:
                        score = 0
                    print(f"    {i}. {model['name']} ({model['organization']}): {score:.1f}åˆ†")
                if len(mock_models) > 5:
                    print(f"    ... è¿˜æœ‰ {len(mock_models) - 5} ä¸ª")
                
                # ç¡®è®¤åˆ é™¤
                print("\nâš ï¸ å³å°†åˆ é™¤æ‰€æœ‰Mockæ¨¡å‹ï¼Œæ­¤æ“ä½œä¸å¯æ¢å¤ï¼")
                
                # æ‰§è¡Œåˆ é™¤
                deleted = 0
                failed = 0
                
                for model in mock_models:
                    model_id = model.get('id')
                    model_name = model.get('name', 'Unknown')
                    
                    if await self.delete_model(model_id):
                        deleted += 1
                        print(f"  âœ… åˆ é™¤æˆåŠŸ: {model_name}")
                    else:
                        failed += 1
                        print(f"  âŒ åˆ é™¤å¤±è´¥: {model_name}")
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    if (deleted + failed) % 10 == 0:
                        print(f"    è¿›åº¦: {deleted + failed}/{len(mock_models)}")
                
                print(f"\nğŸ“Š åˆ é™¤ç»“æœ:")
                print(f"  æˆåŠŸåˆ é™¤: {deleted} ä¸ª")
                print(f"  åˆ é™¤å¤±è´¥: {failed} ä¸ª")
                
                return deleted > 0
            else:
                print("\nâœ… æ²¡æœ‰Mockæ¨¡å‹éœ€è¦åˆ é™¤")
                return True
                
        except Exception as e:
            print(f"âŒ æ¸…ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def verify_result(self):
        """éªŒè¯æ¸…ç†ç»“æœ"""
        try:
            print("\nğŸ” éªŒè¯æ¸…ç†ç»“æœ...")
            
            # è·å–å½“å‰æ‰€æœ‰æ¨¡å‹
            models = await self.get_all_models()
            
            # åˆ†ç±»ç»Ÿè®¡
            benchmark_count = 0
            mock_count = 0
            
            for model in models:
                if model.get('data_source') == 'benchmark':
                    benchmark_count += 1
                else:
                    mock_count += 1
            
            print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            print(f"  æ€»æ¨¡å‹æ•°: {len(models)}")
            print(f"  Benchmarkæ¨¡å‹: {benchmark_count} ä¸ª")
            print(f"  Mockæ¨¡å‹: {mock_count} ä¸ª")
            
            if mock_count == 0 and benchmark_count > 0:
                print("\nâœ… æ¸…ç†æˆåŠŸï¼åªå‰©Benchmarkæ¨¡å‹")
                
                # æ˜¾ç¤ºå‰5å
                benchmark_models = [m for m in models if m.get('data_source') == 'benchmark']
                benchmark_models.sort(key=lambda x: x.get('overall_score', 0), reverse=True)
                
                print("\nğŸ† Top 5 Benchmarkæ¨¡å‹:")
                for i, model in enumerate(benchmark_models[:5], 1):
                    score = model.get('overall_score', 0)
                    if score is None:
                        score = 0
                    print(f"  {i}. {model['name']} ({model['organization']}): {score:.1f}åˆ†")
                
                return True
            else:
                print(f"\nâš ï¸ è¿˜æœ‰ {mock_count} ä¸ªMockæ¨¡å‹æœªæ¸…ç†")
                return False
                
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return False
    
    async def run(self):
        """æ‰§è¡Œå®Œæ•´çš„æ¸…ç†æµç¨‹"""
        print("="*60)
        print("ğŸ§¹ æ¸…ç†Mockæ¨¡å‹æ•°æ®")
        print("="*60)
        
        # 1. ç™»å½•
        if not await self.login():
            print("âŒ æ— æ³•ç™»å½•ï¼Œè¯·æ£€æŸ¥è´¦å·å¯†ç ")
            return False
        
        # 2. æ¸…ç†Mockæ¨¡å‹
        if not await self.clean_mock_models():
            print("âš ï¸ æ¸…ç†è¿‡ç¨‹ä¸­æœ‰é”™è¯¯")
        
        # 3. éªŒè¯ç»“æœ
        success = await self.verify_result()
        
        if success:
            print("\nâœ… æ¸…ç†å®Œæˆï¼")
        else:
            print("\nâš ï¸ æ¸…ç†æœªå®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥")
        
        return success

async def main():
    cleaner = MockModelCleaner()
    success = await cleaner.run()
    
    if success:
        print("\nğŸ‰ Mockæ¨¡å‹å·²æˆåŠŸæ¸…ç†!")
        print("ğŸ“± è¯·è®¿é—®å‰ç«¯æŸ¥çœ‹æ•ˆæœ:")
        print("   https://storage.googleapis.com/wenxin-moyun-prod-new-static/index.html#/")
        print("\né¢„æœŸæ•ˆæœ:")
        print("  - åªæ˜¾ç¤º28ä¸ªBenchmarkæ¨¡å‹")
        print("  - æ’åç¬¬ä¸€ï¼šgpt-5 (88.5åˆ†)")
        print("  - æ’åç¬¬äºŒï¼šo1 (88.3åˆ†)")
        print("  - æ’åç¬¬ä¸‰ï¼šgpt-4o (87.3åˆ†)")
    else:
        print("\nâŒ æ¸…ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        sys.exit(1)

if __name__ == "__main__":
    import os
    os.chdir('I:\\website\\wenxin-backend')
    asyncio.run(main())