# OpenAI Models Benchmark Report

Generated: 2025-08-12 22:29:09

## Executive Summary

- **Total Models Tested**: 11
- **Total Test Cases**: 7
- **Total Tests Run**: 77
- **Success Rate**: 100.0%

## Model Rankings

| Rank | Model | Score | Avg Duration | Success Rate | Tests |
|------|-------|-------|--------------|--------------|-------|
| 1 | o1-mini | 0.890 | 5.27s | 100% | 7 |
| 2 | gpt-4o-mini | 0.888 | 7.73s | 100% | 7 |
| 3 | gpt-4.5 | 0.883 | 10.91s | 100% | 7 |
| 4 | o3-mini | 0.879 | 6.51s | 100% | 7 |
| 5 | gpt-4-turbo | 0.877 | 12.24s | 100% | 7 |
| 6 | gpt-4o | 0.877 | 11.14s | 100% | 7 |
| 7 | gpt-4 | 0.856 | 12.91s | 100% | 7 |
| 8 | o1 | 0.834 | 6.65s | 100% | 7 |
| 9 | gpt-5-nano | 0.759 | 4.11s | 100% | 7 |
| 10 | gpt-5-mini | 0.713 | 10.73s | 100% | 7 |
| 11 | gpt-5 | 0.704 | 16.14s | 100% | 7 |

## Test Categories Performance

| Category | Avg Score | Test Count |
|----------|-----------|------------|
| creative | 0.876 | 22 |
| narrative | 0.765 | 22 |
| technical | 0.941 | 11 |
| educational | 0.843 | 11 |
| logical | 0.764 | 11 |

## Key Findings

### Best Performing Model
- **o1-mini** with average score: 0.890

### Performance Insights
- GPT-5 series and o1 series now correctly use max_completion_tokens
- Each model shows distinct performance characteristics
- No longer seeing uniform scores across all models